{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaries = pd.read_csv('audience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinpark/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/kevinpark/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(primaries['tokenized']):\n",
    "    primaries['tokenized'][idx] = i.replace('applaus', '')\n",
    "    \n",
    "for idx, i in enumerate(primaries['tokenized']):\n",
    "    primaries['tokenized'][idx] = i.replace('cheer', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features = 5000)\n",
    "ss = SnowballStemmer(language='english')\n",
    "def stemmer(arr):\n",
    "    '''\n",
    "    takes a corpus in an array and returns a simillar arr of stemmed words\n",
    "    '''\n",
    "    output = list()\n",
    "    for text in arr:\n",
    "        current = \"\"\n",
    "        for word in text.split():\n",
    "            current += ss.stem(word) + \" \"\n",
    "        output.append(current)\n",
    "    return output\n",
    "\n",
    "def document_vectorizer(arr):\n",
    "    step1 = stemmer(arr)\n",
    "    step2 = vectorizer.fit_transform(np.array(step1))\n",
    "    data = pd.DataFrame(step2.toarray(), columns = vectorizer.get_feature_names())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_pd = document_vectorizer(primaries['tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vector_pd, primaries['Label2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917437252311757\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_class = nb.predict(X_test)\n",
    "y_prob = nb.predict_proba(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(precision_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "0.7212681638044914\n",
      "0.1315136476426799\n",
      "0.424\n",
      "Logistic Regression\n",
      "0.7992073976221928\n",
      "0.14901960784313725\n",
      "0.304\n",
      "Random Forest\n",
      "0.8645970937912814\n",
      "0.10784313725490197\n",
      "0.088\n",
      "SVC\n",
      "0.8540290620871862\n",
      "0.17567567567567569\n",
      "0.208\n"
     ]
    }
   ],
   "source": [
    "cheer = X[X.Label2 == 1]\n",
    "not_cheer = X[X.Label2 == 0]\n",
    "\n",
    "cheer_upsampled = resample(cheer,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_cheer), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_cheer, cheer_upsampled])\n",
    "\n",
    "y_train = upsampled.Label2\n",
    "X_train = upsampled.drop('Label2', axis=1)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_class = nb.predict(X_test)\n",
    "y_prob = nb.predict_proba(X_test)\n",
    "print('Multinomial NB')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(precision_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred_class = lr.predict(X_test)\n",
    "lr_prob = lr.predict_proba(X_test)\n",
    "print('Logistic Regression')\n",
    "print(accuracy_score(y_test, lr_pred_class))\n",
    "print(precision_score(y_test, lr_pred_class))\n",
    "print(recall_score(y_test, lr_pred_class))\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred_class = rfc.predict(X_test)\n",
    "rfc_prob = rfc.predict_proba(X_test)\n",
    "print('Random Forest')\n",
    "print(accuracy_score(y_test, rfc_pred_class))\n",
    "print(precision_score(y_test, rfc_pred_class))\n",
    "print(recall_score(y_test, rfc_pred_class))\n",
    "print('SVC')\n",
    "svm = LinearSVC(class_weight = 'balanced', random_state = 27)\n",
    "clf = CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_prob = clf.predict_proba(X_test)\n",
    "print(accuracy_score(y_test, clf_pred))\n",
    "print(precision_score(y_test, clf_pred))\n",
    "print(recall_score(y_test, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.57045886, -9.57045886, -9.57045886, ..., -8.59841678,\n",
       "        -9.57045886, -9.57045886]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, mnb, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(mnb.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print (\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-9.5705\t01             \t\t-4.6061\tthank          \n",
      "\t-9.5705\t025            \t\t-4.8772\tthink          \n",
      "\t-9.5705\t065            \t\t-4.9874\tpeopl          \n",
      "\t-9.5705\t08             \t\t-4.9939\tpresid         \n",
      "\t-9.5705\t10             \t\t-5.0539\tlet            \n",
      "\t-9.5705\t10000          \t\t-5.1048\twork           \n",
      "\t-9.5705\t100000         \t\t-5.2271\tmake           \n",
      "\t-9.5705\t1010           \t\t-5.3021\tunit           \n",
      "\t-9.5705\t10th           \t\t-5.3264\tcountri        \n",
      "\t-9.5705\t11000          \t\t-5.3582\twant           \n",
      "\t-9.5705\t112            \t\t-5.4476\tstate          \n",
      "\t-9.5705\t118000         \t\t-5.4909\tneed           \n",
      "\t-9.5705\t11th           \t\t-5.4913\tamerican       \n",
      "\t-9.5705\t12             \t\t-5.5189\tamerica        \n",
      "\t-9.5705\t12000          \t\t-5.5967\tlike           \n",
      "\t-9.5705\t1280           \t\t-5.6106\tyes            \n",
      "\t-9.5705\t12th           \t\t-5.6270\tstreet         \n",
      "\t-9.5705\t13             \t\t-5.6283\tknow           \n",
      "\t-9.5705\t1300           \t\t-5.6446\twall           \n",
      "\t-9.5705\t13000          \t\t-5.6631\trepublican     \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, mnb, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e43a45400549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mclf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m                         sample_weight=base_estimator_sample_weight[train])\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0mthis_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 calibrated_classifier = _CalibratedClassifier(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cheer = X[X.Label2 == 1]\n",
    "not_cheer = X[X.Label2 == 0]\n",
    "\n",
    "y_train = upsampled.Label2\n",
    "X_train = upsampled.drop('Label2', axis=1)\n",
    "\n",
    "svm = SVC(class_weight = 'balanced', random_state = 27)\n",
    "clf = CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_prob = clf.predict_proba(X_test)\n",
    "print(accuracy_score(y_test, clf_pred))\n",
    "print(precision_score(y_test, clf_pred))\n",
    "print(recall_score(y_test, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = pd.read_csv('Presidential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = document_vectorizer(primaries['tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vector, primaries['Labels2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb = MultinomialNB()\n",
    "# nb.fit(X_train, y_train)\n",
    "# y_pred_class = nb.predict(X_test)\n",
    "# y_prob = nb.predict_proba(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(precision_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred_class = lr.predict(X_test)\n",
    "lr_prob = lr.predict_proba(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, lr_pred_class))\n",
    "print(precision_score(y_test, lr_pred_class))\n",
    "print(recall_score(y_test, lr_pred_class))\n",
    "\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_train, y_train)\n",
    "# rfc_pred_class = rfc.predict(X_test)\n",
    "# rfc_prob = rfc.predict_proba(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, rfc_pred_class))\n",
    "print(precision_score(y_test, rfc_pred_class))\n",
    "print(recall_score(y_test, rfc_pred_class))\n",
    "\n",
    "svm = LinearSVC(class_weight = 'balanced', random_state = 27)\n",
    "clf = CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_prob = clf.predict_proba(X_test)\n",
    "print(accuracy_score(y_test, clf_pred))\n",
    "print(precision_score(y_test, clf_pred))\n",
    "print(recall_score(y_test, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_values(prob, y):\n",
    "    '''\n",
    "    Build dataframe of the various confusion-matrix ratios by threshold\n",
    "    from a list of predicted probabilities and actual y values\n",
    "    '''\n",
    "    df = pd.DataFrame({'prob': prob, 'y': y})\n",
    "    df.sort_values('prob', inplace=True)\n",
    "    \n",
    "    actual_p = df.y.sum()\n",
    "    actual_n = df.shape[0] - df.y.sum()\n",
    "\n",
    "    df['tn'] = (df.y == 0).cumsum()\n",
    "    df['fn'] = df.y.cumsum()\n",
    "    df['fp'] = actual_n - df.tn\n",
    "    df['tp'] = actual_p - df.fn\n",
    "\n",
    "    df['fpr'] = df.fp/(df.fp + df.tn)\n",
    "    df['tpr'] = df.tp/(df.tp + df.fn)\n",
    "    df['precision'] = df.tp/(df.tp + df.fp)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "def plot_roc(ax, df):\n",
    "    ax.plot([1]+list(df.fpr), [1]+list(df.tpr), label=\"ROC\")\n",
    "    ax.plot([0,1],[0,1], 'k', label=\"random\")\n",
    "    ax.set_xlabel('fpr')\n",
    "    ax.set_ylabel('tpr')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_precision_recall(ax, df):\n",
    "    ax.plot(df.tpr,df.precision, label='precision/recall')\n",
    "    #ax.plot([0,1],[0,1], 'k')\n",
    "    ax.set_xlabel('recall')\n",
    "    ax.set_ylabel('precision')\n",
    "    ax.set_title('Precision/Recall Curve')\n",
    "    ax.plot([0,1],[df.precision[0],df.precision[0]], 'k', label='random')\n",
    "    ax.set_xlim(xmin=0,xmax=1)\n",
    "    ax.set_ylim(ymin=0,ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_prob[:,1])\n",
    "    \n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred_class.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "lpr = dict()\n",
    "ipr = dict()\n",
    "\n",
    "loc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    lpr[i], ipr[i], _ = roc_curve(y_test, clf_prob[:,1])\n",
    "    \n",
    "lpr[\"micro\"], ipr[\"micro\"], _ = roc_curve(y_test.ravel(), clf_pred.ravel())\n",
    "loc_auc[\"micro\"] = auc(lpr[\"micro\"], ipr[\"micro\"])\n",
    "\n",
    "rpr = dict()\n",
    "dpr = dict()\n",
    "doc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    rpr[i], dpr[i], _ = roc_curve(y_test, rfc_prob[:,1])\n",
    "    \n",
    "rpr[\"micro\"], dpr[\"micro\"], _ = roc_curve(y_test.ravel(), rfc_pred_class.ravel())\n",
    "doc_auc[\"micro\"] = auc(rpr[\"micro\"], dpr[\"micro\"])\n",
    "\n",
    "xpr = dict()\n",
    "zpr = dict()\n",
    "doc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    xpr[i], zpr[i], _ = roc_curve(y_test, lr_prob[:,1])\n",
    "    \n",
    "xpr[\"micro\"], zpr[\"micro\"], _ = roc_curve(y_test.ravel(), lr_pred_class.ravel())\n",
    "doc_auc[\"micro\"] = auc(xpr[\"micro\"], zpr[\"micro\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "lw = 5\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='MultinomialNB')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.plot(lpr[1], ipr[1], color='green',\n",
    "        lw=5, label='Linear SVC')\n",
    "plt.plot(rpr[1], dpr[1], color = 'red',\n",
    "        lw=lw, label = 'Random Forest')\n",
    "plt.plot(xpr[1], zpr[1], color = 'purple',\n",
    "        lw=lw, label = 'Logistic Regression')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.xticks(fontsize = 24)\n",
    "plt.yticks(fontsize = 24)\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 36)\n",
    "plt.ylabel('True Positive Rate', fontsize = 36)\n",
    "plt.title('ROC Curves', fontsize = 48)\n",
    "plt.legend(loc=\"lower right\", fontsize= 36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_threshold_values(lr_pred_class, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_pred_class).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitff3a9920a6464dc8ae877e40204d8aad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
